from __future__ import annotations

import logging
from typing import List

from pdf2image import convert_from_path
from PIL import Image
import numpy as np

logger = logging.getLogger(__name__)


class OCRError(RuntimeError):
    """ç»Ÿä¸€æŠ› OCR ç›¸å…³é”™è¯¯"""
    pass


# ---------------------------
# é¢„å¤„ç† & è§„èŒƒåŒ–
# ---------------------------
def preprocess_image(image: Image.Image) -> np.ndarray:
    """æ¸©å’Œé¢„å¤„ç†ï¼šç°åº¦ + è½»åº¦å»å™ª + è½»å¾®å¯¹æ¯”å¢å¼ºï¼ˆä¸åšäºŒå€¼åŒ–ï¼Œé¿å…ç»†å­—ä¸¢å¤±ï¼‰"""
    import cv2  # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…ç¯å¢ƒæ²¡è£…æ—¶å½±å“æ¨¡å—åŠ è½½
    img = np.array(image)
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    # è½»åº¦é™å™ªï¼Œä¿è¾¹
    gray = cv2.bilateralFilter(gray, d=5, sigmaColor=50, sigmaSpace=50)
    # è½»å¾®å¯¹æ¯”æ‹‰ä¼¸
    gray = cv2.convertScaleAbs(gray, alpha=1.15, beta=0)
    # è¿˜åŸæˆ3é€šé“ï¼Œå…¼å®¹ä¸‹æ¸¸
    return cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)


def _normalize_visible_text(s: str) -> str:
    """OCRåç»Ÿä¸€è§„èŒƒï¼šå…¨è§’â†’åŠè§’ï¼Œå‹ç©ºç™½ï¼Œè½¬å¤§å†™"""
    import unicodedata
    if not s:
        return ""
    s = unicodedata.normalize("NFKC", s)
    s = " ".join(s.split())
    return s.upper()


# ---------------------------
# YomiToku è¾“å‡ºå…¼å®¹é€‚é…å™¨
# ---------------------------
def _to_texts_from_result(res) -> List[str]:
    """
    æŠŠ YomiToku çš„è¿”å›ç»“æœç»Ÿä¸€æŠ½æˆ [page_text, ...]
    å…¼å®¹ï¼š
      - obj.blocks / obj.pages[*].blocks / obj.lines / obj.paragraphs
      - dict: {"pages":[...]} / {"results":[...]} / {"text":"..."}
      - list[dict/obj] / tuple(...)
    """
    def _text_from_block(b):
        for k in ("text", "content", "string"):
            if hasattr(b, k):
                v = getattr(b, k, "")
                if isinstance(v, str):
                    return v
            elif isinstance(b, dict) and isinstance(b.get(k), str):
                return b[k]
        return ""

    def _blocks_from_page(p):
        for attr in ("blocks", "lines", "paragraphs"):
            if hasattr(p, attr):
                xs = getattr(p, attr) or []
                return [x for x in xs if x is not None]
        if isinstance(p, dict):
            for key in ("blocks", "lines", "paragraphs"):
                xs = p.get(key)
                if isinstance(xs, list):
                    return [x for x in xs if x is not None]
        return []

    # tupleï¼šå–ç¬¬ä¸€ä¸ªåƒç»“æ„ä½“çš„
    if isinstance(res, tuple):
        for item in res:
            if item is None:
                continue
            if isinstance(item, (dict, list)) or any(
                hasattr(item, a) for a in ("blocks", "pages", "lines", "paragraphs")
            ):
                res = item
                break

    # dict
    if isinstance(res, dict):
        if isinstance(res.get("pages"), list):
            texts = []
            for p in res["pages"]:
                blocks = _blocks_from_page(p)
                texts.append(" ".join(filter(None, (_text_from_block(b) for b in blocks))))
            return texts
        if isinstance(res.get("results"), list):
            return [" ".join(filter(None, [
                (r.get("content") if isinstance(r, dict) else getattr(r, "content", "")) or
                (r.get("text")    if isinstance(r, dict) else getattr(r, "text", ""))
                for r in res["results"]
            ]))]
        if isinstance(res.get("text"), str):
            return [res["text"]]
        raise OCRError(f"YomiToku OCR: æœªçŸ¥dictå½¢å¼: keys={list(res.keys())[:6]}")

    # list
    if isinstance(res, list):
        if not res:
            return [""]
        page_like = any(
            isinstance(x, dict) and any(k in x for k in ("blocks", "lines", "paragraphs", "text", "content"))
            or any(hasattr(x, a) for a in ("blocks", "lines", "paragraphs", "text", "content"))
            for x in res
        )
        if page_like:
            texts = []
            for p in res:
                if isinstance(p, dict) and any(k in p for k in ("text", "content")):
                    texts.append(_text_from_block(p))
                elif any(hasattr(p, a) for a in ("text", "content")):
                    texts.append(_text_from_block(p))
                else:
                    blocks = _blocks_from_page(p)
                    texts.append(" ".join(filter(None, (_text_from_block(b) for b in blocks))))
            return texts
        return [" ".join(filter(None, (_text_from_block(b) for b in res)))]

    # å¯¹è±¡ï¼šä¼˜å…ˆ pages
    if hasattr(res, "pages"):
        pages = getattr(res, "pages") or []
        texts = []
        for p in pages:
            blocks = _blocks_from_page(p)
            texts.append(" ".join(filter(None, (_text_from_block(b) for b in blocks))))
        return texts

    # æ¬¡ä¼˜ï¼šblocks/lines/paragraphs
    for attr in ("blocks", "lines", "paragraphs"):
        if hasattr(res, attr):
            blocks = getattr(res, attr) or []
            return [" ".join(filter(None, (_text_from_block(b) for b in blocks)))]

    raise OCRError("YomiTokuã®OCRçµæœã®å½¢å¼ã‚’è§£é‡ˆã§ãã¾ã›ã‚“ï¼ˆæœªçŸ¥ã®å‡ºåŠ›ï¼‰ã€‚")


# ---------------------------
# OCR æ‰§è¡Œå™¨ï¼ˆYomiToku + Tesseract å…œåº•ï¼‰
# ---------------------------
def _run_yomitoku(analyzer, np_img: np.ndarray) -> str:
    result = analyzer(np_img)
    page_texts = _to_texts_from_result(result)
    return _normalize_visible_text(" ".join(t for t in page_texts if t))


def _run_tesseract(np_img: np.ndarray) -> str:
    """å…œåº•ï¼šç”¨ tesseract æŠ“è‹±æ•°å­—ï¼ˆé€‚åˆ NNF41030 / XLX460UEN è¿™ç§å°åˆ·ä½“ï¼‰"""
    try:
        import cv2
        import pytesseract
    except Exception:
        return ""
    gray = cv2.cvtColor(np_img, cv2.COLOR_BGR2GRAY)
    _, bw = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY)
    text = pytesseract.image_to_string(bw, lang="eng+jpn")
    return _normalize_visible_text(text)


def ocr_pages(pdf_path: str, dpi: int = 300) -> List[str]:
    """æŠŠ PDF æ¯é¡µè½¬å›¾è¯†åˆ«ï¼Œè¿”å›æ¯é¡µåˆå¹¶åçš„æ–‡æœ¬ï¼ˆå·²åšå…¨è§’è½¬åŠè§’å’Œå¤§å†™ï¼‰"""
    try:
        from yomitoku import DocumentAnalyzer
    except ImportError as exc:  # pragma: no cover
        raise OCRError(
            "YomiTokuãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚"
        ) from exc

    try:
        images = convert_from_path(pdf_path, dpi=dpi)
    except Exception as exc:  # pragma: no cover
        raise OCRError("pdf2imageãŒPDFã‚’å‡¦ç†ã§ãã¾ã›ã‚“ã€‚Popplerã®å°å…¥ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚") from exc

    analyzer = DocumentAnalyzer()
    texts: List[str] = []

    for idx, image in enumerate(images):
        processed = preprocess_image(image)
        raw_np = np.array(image)

        # 1) YomiToku è·¯çº¿ï¼šé¢„å¤„ç†å›¾ vs åŸå›¾ï¼Œå–æ›´é•¿
        try:
            yomi_processed = _run_yomitoku(analyzer, processed)
            yomi_raw = _run_yomitoku(analyzer, raw_np)
        except Exception:  # pragma: no cover
            logger.exception("YomiToku OCR failed on page %d", idx + 1)
            yomi_processed = yomi_raw = ""

        best_yomi = max((yomi_processed, yomi_raw), key=len)

        # 2) æ–‡æœ¬å¤ªçŸ­ï¼ˆ<10ï¼‰ï¼Œå†ç”¨ tesseract å…œåº•
        tess = _run_tesseract(processed) if len(best_yomi) < 10 else ""
        final_text = max((best_yomi, tess), key=len)

        # 3) æ‰“æ ·æ—¥å¿—
        logger.info("ğŸ“„ Page %d sample: %r", idx + 1, final_text[:160])

        texts.append(final_text)

    return texts
